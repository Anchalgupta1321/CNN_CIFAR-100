{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa9c2a9e-e3ac-49bf-99f6-2930b28b5b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Minimum number of images per class: 500\n",
      "CIFAR-100 data successfully divided into train, val, and test splits with equal class distribution.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "cifar100 = datasets.CIFAR100(root='./data', download=True)\n",
    "\n",
    "# Function to create directories if they don't exist\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Base path for the organized data\n",
    "base_dir = './cifar100_data_split'\n",
    "\n",
    "# Superclass to classes mapping (manually mapping specific classes for each superclass)\n",
    "superclass_to_classes = {\n",
    "    \"aquatic_mammals\": [\"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\"],\n",
    "    \"fish\": [\"aquarium_fish\", \"flatfish\", \"ray\", \"shark\", \"trout\"],\n",
    "    \"food containers\": [\"bottle\", \"bowl\", \"can\", \"cup\", \"plate\"],\n",
    "    \"fruit and vegetables\": [\"apple\", \"orange\", \"mushrooms\", \"pear\", \"sweet_peppers\"],\n",
    "    \"household electrical devices\": [\"clock\", \"keyboard\", \"lamp\", \"telephone\", \"television\"],\n",
    "    \"household furniture\": [\"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\"],\n",
    "    \"insects\": [\"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\"],\n",
    "    \"large carnivores\": [\"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\"],\n",
    "    \"large man-made outdoor things\": [\"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\"],\n",
    "    \"large natural outdoor scenes\": [\"cloud\", \"forest\", \"mountain\", \"plain\", \"sea\"],\n",
    "    \"large omnivores and herbivores\": [\"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\"],\n",
    "    \"medium-sized mammals\": [\"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\"],\n",
    "    \"non-insect invertebrates\": [\"crab\", \"lobster\", \"snail\", \"spider\", \"worm\"],\n",
    "    \"people\": [\"baby\", \"boy\", \"girl\", \"man\", \"woman\"],\n",
    "    \"reptiles\": [\"crocodile\", \"lizard\", \"snake\", \"turtle\", \"dinosaur\"],\n",
    "    \"small mammals\": [\"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\"],\n",
    "    \"trees\": [\"maple_tree\", \"oak_tree\", \"palm_tree\", \"pine_tree\", \"willow_tree\"],\n",
    "    \"vehicles 1\": [\"bicycle\", \"bus\", \"motorcycle\", \"pickup_truck\", \"train\"],\n",
    "    \"vehicles 2\": [\"lawn_mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\"]\n",
    "}\n",
    "\n",
    "# Function to ensure that we have equal number of images for each class under each superclass\n",
    "def get_balanced_data_for_superclass():\n",
    "    data_by_class = defaultdict(list)\n",
    "    \n",
    "    # Collect the indices of the images per class\n",
    "    for idx, label in enumerate(cifar100.targets):\n",
    "        class_name = cifar100.classes[label]\n",
    "        # Only collect data for classes that belong to the current superclass\n",
    "        for superclass, class_list in superclass_to_classes.items():\n",
    "            if class_name in class_list:\n",
    "                data_by_class[class_name].append(idx)\n",
    "    \n",
    "    # Ensure equal number of images by finding the minimum number of images in any class\n",
    "    min_images_per_class = min(len(images) for images in data_by_class.values())\n",
    "    print(f\"Minimum number of images per class: {min_images_per_class}\")\n",
    "    \n",
    "    # Randomly sample images to ensure equal class distribution\n",
    "    balanced_indices = {}\n",
    "    for class_name, indices in data_by_class.items():\n",
    "        balanced_indices[class_name] = random.sample(indices, min_images_per_class)\n",
    "    \n",
    "    return balanced_indices\n",
    "\n",
    "# Split data into train, val, and test sets\n",
    "def split_data_into_train_val_test(balanced_indices):\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    # Split data into train, val, test for each class\n",
    "    for class_name, indices in balanced_indices.items():\n",
    "        train, temp = train_test_split(indices, test_size=0.5, random_state=42)\n",
    "        val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "        \n",
    "        train_data.extend(train)\n",
    "        val_data.extend(val)\n",
    "        test_data.extend(test)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Function to save images into the correct directory structure\n",
    "def save_images(data, split_name):\n",
    "    for idx in data:\n",
    "        image, label = cifar100[idx]\n",
    "        class_name = cifar100.classes[label]\n",
    "        \n",
    "        # Find the superclass based on class_name\n",
    "        for superclass, class_list in superclass_to_classes.items():\n",
    "            if class_name in class_list:\n",
    "                break\n",
    "        \n",
    "        # Create destination path\n",
    "        dest_dir = os.path.join(base_dir, split_name, superclass, class_name)\n",
    "        create_dir(dest_dir)  # Make sure the destination directory exists\n",
    "        \n",
    "        # Save the image to the destination folder\n",
    "        image_name = f\"{idx}.png\"  # Use the index as the filename\n",
    "        image.save(os.path.join(dest_dir, image_name))\n",
    "\n",
    "# Main function to create directories, balance data, and save images\n",
    "def main():\n",
    "    # Create base directories\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for superclass in superclass_to_classes:\n",
    "            for class_name in superclass_to_classes[superclass]:\n",
    "                class_path = os.path.join(base_dir, split, superclass, class_name)\n",
    "                create_dir(class_path)\n",
    "    \n",
    "    # Get balanced data for each superclass\n",
    "    balanced_indices = get_balanced_data_for_superclass()\n",
    "    \n",
    "    # Split data into train, val, and test sets\n",
    "    train_data, val_data, test_data = split_data_into_train_val_test(balanced_indices)\n",
    "    \n",
    "    # Save the images in their respective directories\n",
    "    save_images(train_data, 'train')\n",
    "    save_images(val_data, 'val')\n",
    "    save_images(test_data, 'test')\n",
    "    \n",
    "    print(\"CIFAR-100 data successfully divided into train, val, and test splits with equal class distribution.\")\n",
    "\n",
    "# Run the process\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f96d2f1-db31-4315-a20e-9f3a419267a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c355589-6541-4716-9eae-15d8fa9f49ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "401cd4a6-f774-4100-94d1-db1f348a0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Paths\n",
    "train_dir=r'C:\\Users\\user\\Desktop\\Deep Learning\\CNN-CIFAR-100\\cifar100_data_split\\test'\n",
    "test_dir=r'C:\\Users\\user\\Desktop\\Deep Learning\\CNN-CIFAR-100\\cifar100_data_split\\train'\n",
    "val_dir=r'C:\\Users\\user\\Desktop\\Deep Learning\\CNN-CIFAR-100\\cifar100_data_split\\val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db31f5ec-3a0d-47e3-891b-d32066a5be8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train directory structure:\n",
      "aquatic_mammals ['beaver', 'dolphin', 'otter', 'seal', 'whale']\n",
      "fish ['aquarium_fish', 'flatfish', 'ray', 'shark', 'trout']\n",
      "food containers ['bottle', 'bowl', 'can', 'cup', 'plate']\n",
      "fruit and vegetables ['apple', 'mushrooms', 'orange', 'pear', 'sweet_peppers']\n",
      "household electrical devices ['clock', 'keyboard', 'lamp', 'telephone', 'television']\n",
      "household furniture ['bed', 'chair', 'couch', 'table', 'wardrobe']\n",
      "insects ['bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach']\n",
      "large carnivores ['bear', 'leopard', 'lion', 'tiger', 'wolf']\n",
      "large man-made outdoor things ['bridge', 'castle', 'house', 'road', 'skyscraper']\n",
      "large natural outdoor scenes ['cloud', 'forest', 'mountain', 'plain', 'sea']\n",
      "large omnivores and herbivores ['camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo']\n",
      "medium-sized mammals ['fox', 'porcupine', 'possum', 'raccoon', 'skunk']\n",
      "non-insect invertebrates ['crab', 'lobster', 'snail', 'spider', 'worm']\n",
      "people ['baby', 'boy', 'girl', 'man', 'woman']\n",
      "reptiles ['crocodile', 'dinosaur', 'lizard', 'snake', 'turtle']\n",
      "small mammals ['hamster', 'mouse', 'rabbit', 'shrew', 'squirrel']\n",
      "trees ['maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree']\n",
      "vehicles 1 ['bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train']\n",
      "vehicles 2 ['lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor']\n"
     ]
    }
   ],
   "source": [
    "# Check Directory and Files Manually\n",
    "import os\n",
    "\n",
    "print(\"Train directory structure:\")\n",
    "for superclass in os.listdir(train_dir):\n",
    "    print(superclass, os.listdir(os.path.join(train_dir, superclass)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06c7b93-3b09-4c40-802b-675137b2d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization and augmentation\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Example normalization\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e7b513-62b6-4917-a1c9-adfe9aae782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "train_dataset=datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset=datasets.ImageFolder(test_dir, transform=transform)\n",
    "val_dataset=datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)\n",
    "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb4a28aa-dad8-401b-ae9e-c2a45ee58112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1) # Conv Layer 1\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # Pooling Loyer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) # Conv Layer 2\n",
    "        self.fc1 = nn.Linear(64*8*8, 128) # Fully connected Layer\n",
    "        self.fc2 = nn.Linear(128, 95)\n",
    "        \n",
    "# Output layer for 10 classes\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*8*8) #Flatten\n",
    "        x = nn.functional.relu(self.fc1(x)) # Fully connected Layer\n",
    "        x = self.fc2(x) # Output Layer\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model=CNN().to(device)    # move model to GPU\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2b8ba86-4dfc-475d-af2f-8b5d9dc655ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.5671\n",
      "Epoch [2/10], Loss: 2.1455\n",
      "Epoch [3/10], Loss: 1.9230\n",
      "Epoch [4/10], Loss: 1.7339\n",
      "Epoch [5/10], Loss: 1.5384\n",
      "Epoch [6/10], Loss: 1.3521\n",
      "Epoch [7/10], Loss: 1.1618\n",
      "Epoch [8/10], Loss: 0.9798\n",
      "Epoch [9/10], Loss: 0.7810\n",
      "Epoch [10/10], Loss: 0.6023\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # move data to GPU\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs =model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "    print (f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b42dfc9e-e25b-4078-848e-de013ff8e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  40.292473%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Move data to GPU\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch. max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy: 2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1e360c9-b4f3-44cf-953f-27d8847ef0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  39.698925%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        # Move data to GPU\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch. max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "val_accuracy = 100 * correct / total\n",
    "print(f\"Validation Accuracy: {val_accuracy: 2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b548f-0dc5-4a90-b4bc-d08305fa190e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22cfae-c022-4742-8232-5f5d605954b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec134be7-4a3f-4d37-9209-8dca7e033944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
